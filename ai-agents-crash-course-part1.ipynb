{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8d69ff3",
   "metadata": {},
   "source": [
    "# AI Agents Crash Course\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Project Setup](#project-setup)\n",
    "   - [Load Required Python Modules and Libraries](#load-required-python-modules-and-libraries)\n",
    "   - [Load Environment Variables and Configure LLM](#load-environment-variables-and-configure-llm)\n",
    "   - [Configure LLM](#configure-llm)\n",
    "\n",
    "2. [Single Agent Single Tool Example](#single-agent-single-tool-example)\n",
    "   - [Define Agents](#define-agents)\n",
    "   - [Define a Writing Task](#define-a-writing-task)\n",
    "   - [Create a Crew and Execute the Task](#create-a-crew-and-execute-the-task)\n",
    "   - [Save the Response to a File](#save-the-response-to-a-file)\n",
    "\n",
    "3. [File Reading Tools](#file-reading-tools)\n",
    "   - [Define a file reader tool (OPENAI ONLY)](#define-a-file-reader-tool-openai-only---does-not-work-with-ollama-models)\n",
    "   - [Troubleshooting Note](#troubleshooting-note)\n",
    "   - [Define the Agent For Reading And Summarizing Files (OPENAI ONLY)](#define-the-agent-for-reading-and-summarizing-files-openai-only)\n",
    "   - [Create Reading and Analyzing File Task (OPENAI ONLY)](#create-reading-and-analyzing-file-task-openai-only)\n",
    "   - [Assemble A File-Processing Crew Workflow (OPENAI ONLY)](#assemble-a-file-processing-crew-workflow-openai-only)\n",
    "\n",
    "4. [Building Multi-Agent Systems](#building-multi-agent-systems)\n",
    "   - [Define our Serper Dev tool](#define-our-serper-dev-tool)\n",
    "   - [Define the Internet Researcher Agent and Task](#define-the-internet-researcher-agent-and-task)\n",
    "   - [Define The Summarization Agent](#define-the-summarization-agent)\n",
    "   - [Define The Fact-Checking Agent](#define-the-fact-checking-agent)\n",
    "   - [Create Multi-Agent Crew Workflow](#create-multi-agent-crew-workflow)\n",
    "   - [Kickoff The Multi-Agent Crew Workflow](#kickoff-the-multi-agent-crew-workflow)\n",
    "\n",
    "5. [Using YAML Based Agent and Workflow Definition](#using-yaml-based-agent-and-workflow-definition)\n",
    "   - [Load YAML File](#load-yaml-file)\n",
    "   - [Convert Agent Definitions to use YAML Config Details](#convert-agent-definitions-to-use-yaml-config-details)\n",
    "   - [Create Multi-Agent Crew Workflow](#create-multi-agent-crew-workflow-1)\n",
    "\n",
    "---\n",
    "\n",
    "This notebook demonstrates various CrewAI features including:\n",
    "- ‚úÖ Single-agent workflows with basic tasks\n",
    "- ‚úÖ Multi-agent sequential workflows\n",
    "- ‚úÖ Tool integration (SerperDevTool for web search)\n",
    "- ‚ö†Ô∏è  File reading tools (OpenAI compatible only)\n",
    "- ‚úÖ YAML-based configuration\n",
    "- ‚úÖ LiteLLM debugging for troubleshooting\n",
    "- ‚úÖ Support for both OpenAI and Ollama LLMs\n",
    "\n",
    "**Note on Ollama Compatibility**: File reading tools (FileReadTool) currently have compatibility issues with Ollama-based models due to a bug in the litellm/ollama integration. This notebook includes troubleshooting steps for this limitation.\n",
    "\n",
    "---\n",
    "\n",
    "REFERENCE:  https://www.dailydoseofds.com/ai-agents-crash-course-part-1-with-implementation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971de429",
   "metadata": {},
   "source": [
    "# Project Setup\n",
    "\n",
    "This notebook will guide you through setting up the project environment for using CrewAI. We will:\n",
    "\n",
    "1. Install the required Python modules.\n",
    "2. Set up a virtual environment.\n",
    "3. Verify the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61fcc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you are not using devcontainers and want to set up a local environment\n",
    "# \n",
    "# # Step 1: Create and activate a virtual environment\n",
    "# #\n",
    "# %python3 -m venv venv\n",
    "# %source venv/bin/activate\n",
    "# \n",
    "# # Step 2: Install required Python modules\n",
    "# #\n",
    "# %pip install -r requirements.txt\n",
    "# \n",
    "# # Step 3: Verify installation\n",
    "# #\n",
    "# %pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f46cb",
   "metadata": {},
   "source": [
    "# Load Required Python Modules and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown\n",
    "from crewai import LLM, Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LiteLLM Debug Control\n",
    "# Run this cell to easily enable or disable litellm debugging\n",
    "import litellm\n",
    "\n",
    "def enable_litellm_debug():\n",
    "    \"\"\"Enable litellm debugging for detailed error diagnostics\"\"\"\n",
    "    litellm._turn_on_debug()\n",
    "    print(\"‚úÖ LiteLLM debugging ENABLED\")\n",
    "    print(\"   - You will see detailed logs for LLM calls\")\n",
    "    print(\"   - Useful for troubleshooting connection and integration issues\")\n",
    "\n",
    "def disable_litellm_debug():\n",
    "    \"\"\"Disable litellm debugging to reduce verbose output\"\"\"\n",
    "    litellm._turn_off_debug()\n",
    "    print(\"üîá LiteLLM debugging DISABLED\")\n",
    "    print(\"   - Reduced log output for cleaner execution\")\n",
    "\n",
    "def check_litellm_debug_status():\n",
    "    \"\"\"Check if litellm debugging is currently enabled\"\"\"\n",
    "    # litellm doesn't have a direct way to check debug status,\n",
    "    # so we'll check the logging level as a proxy\n",
    "    import logging\n",
    "    logger = logging.getLogger(\"litellm\")\n",
    "    if logger.level <= logging.DEBUG:\n",
    "        print(\"üîç LiteLLM debugging appears to be ENABLED\")\n",
    "    else:\n",
    "        print(\"üîá LiteLLM debugging appears to be DISABLED\")\n",
    "\n",
    "# Uncomment one of the following lines to control debugging:\n",
    "# enable_litellm_debug()    # Enable debugging\n",
    "# disable_litellm_debug()   # Disable debugging\n",
    "check_litellm_debug_status()  # Check current status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a39a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Debug Control - Run any of these cells for immediate control:\n",
    "\n",
    "# üü¢ ENABLE DEBUGGING (run this cell)\n",
    "# enable_litellm_debug()\n",
    "\n",
    "# üî¥ DISABLE DEBUGGING (run this cell)  \n",
    "# disable_litellm_debug()\n",
    "\n",
    "# üîç CHECK STATUS (run this cell)\n",
    "# check_litellm_debug_status()\n",
    "\n",
    "print(\"üí° Tip: Uncomment and run the function you need above, or use the functions from the previous cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29096e08",
   "metadata": {},
   "source": [
    "# Load Environment Variables and Configure LLM\n",
    "\n",
    "This block loads environment variables from the `.env` file, including the OpenAI API Key, which is required to authenticate with OpenAI's services. It then configures the `LLM` object to use OpenAI's GPT-4 model. Alternatively, you can uncomment the provided code to configure the `LLM` object to use Ollama with a local model, provided Ollama is installed and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c357710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# Note: In devcontainer, variables are already loaded by dotenv feature,\n",
    "# but load_dotenv() is safe and won't override existing environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Uncomment the code block below to use OpenAI with your API Key\n",
    "# \n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "# if not api_key:\n",
    "#     raise ValueError(\"OPENAI_API_KEY is not set in the .env file\")\n",
    "\n",
    "# Uncomment the code block below to use ollama\n",
    "# \n",
    "OLLAMA_API_BASE = os.getenv('OLLAMA_API_BASE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae28f8a",
   "metadata": {},
   "source": [
    "# Configure LLM\n",
    "\n",
    "Configures the `LLM` object to use OpenAI's GPT-4 model. \n",
    "\n",
    "Alternatively, you can uncomment the provided code to configure the `LLM` object to use Ollama with a local model, provided Ollama is installed and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34920e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = LLM(\n",
    "#     model=\"gpt-4o\",  # Specify the OpenAI model you want to use\n",
    "#     api_key=api_key\n",
    "# )\n",
    "\n",
    "# Uncomment the code block below to use Ollama with your local model\n",
    "# Make sure to have Ollama installed and running\n",
    "# \n",
    "llm = LLM(\n",
    "    model=\"ollama/openhermes:latest\",\n",
    "    base_url=OLLAMA_API_BASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test ollam connectivity\n",
    "# \n",
    "import requests\n",
    "\n",
    "# Debug: Check environment variables and test Ollama connection\n",
    "# \n",
    "print(\"=== Environment Variables Debug ===\")\n",
    "print(f\"OLLAMA_API_BASE: {OLLAMA_API_BASE}\")\n",
    "test_url = f\"{OLLAMA_API_BASE}/api/tags\"\n",
    "\n",
    "# Test connection to your Ollama server\n",
    "# \n",
    "try:\n",
    "    response = requests.get(test_url, timeout=5)\n",
    "    print(f\"\\n=== Ollama Connection Test ===\")\n",
    "    print(f\"URL: {test_url}\")\n",
    "    print(f\"Status: {response.status_code}\")\n",
    "    print(f\"Response: {response.json()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")\n",
    "\n",
    "# Debug: Check what base_url is actually being used\n",
    "# \n",
    "print(f\"\\n=== CrewAI LLM Connection Test ===\")\n",
    "# print(f\"ollama_base_url from env: {OLLAMA_API_BASE}\")\n",
    "print(f\"LLM base_url: {llm.base_url}\")\n",
    "print(f\"LLM model: {llm.model}\")\n",
    "\n",
    "# Test a simple LLM call\n",
    "try:\n",
    "    test_response = llm.call([{\"role\": \"user\", \"content\": \"Say hello!\"}])\n",
    "    print(\"‚úÖ LLM test successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3cce4d",
   "metadata": {},
   "source": [
    "# Single Agent Single Tool Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a98aa",
   "metadata": {},
   "source": [
    "## Define Agents\n",
    "\n",
    "This block defines multiple agents with specific roles, goals, and backstories. Each agent is configured to use the LLM defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d81170",
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_technical_writer = Agent(\n",
    "    role=\"Senior Technical Writer\",\n",
    "    \n",
    "    goal=\"\"\"Craft clear, engaging, and well-structured\n",
    "            technical content based on research findings\"\"\",\n",
    "    \n",
    "    backstory=\"\"\"You are an experienced technical writer\n",
    "                with expertise in simplifying complex\n",
    "                concepts, structuring content for readability,\n",
    "                and ensuring accuracy in documentation.\"\"\",\n",
    "                \n",
    "    llm=llm,\n",
    "                \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "research_analyst = Agent(\n",
    "    role=\"Senior Research Analyst\",\n",
    "    goal=\"\"\"Find, analyze, and summarize information \n",
    "            from various sources to support technical \n",
    "            and business-related inquiries.\"\"\",\n",
    "    backstory=\"\"\"You are a skilled research analyst with expertise \n",
    "                in gathering accurate data, identifying key trends, \n",
    "                and presenting insights in a structured manner.\"\"\",\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "code_reviewer = Agent(\n",
    "    role=\"Senior Code Reviewer\",\n",
    "    goal=\"\"\"Review code for bugs, inefficiencies, and \n",
    "            security vulnerabilities while ensuring adherence \n",
    "            to best coding practices.\"\"\",\n",
    "    backstory=\"\"\"You are a seasoned software engineer with years of \n",
    "                experience in writing, reviewing, and optimizing \n",
    "                production-level code in multiple programming languages.\"\"\",\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "legal_reviewer = Agent(\n",
    "    role=\"Legal Document Expert Reviewer\",\n",
    "    goal=\"\"\"Review contracts and legal documents to \n",
    "            ensure compliance with applicable laws and \n",
    "            highlight potential risks.\"\"\",\n",
    "    backstory=\"\"\"You are a legal expert with deep knowledge \n",
    "                of contract law, regulatory frameworks, \n",
    "                and risk mitigation strategies.\"\"\",\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129e270",
   "metadata": {},
   "source": [
    "## Define a Writing Task\n",
    "\n",
    "This block defines a writing task for the Senior Technical Writer agent. The task includes a description, the agent responsible, and the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c611c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writing_task = Task(\n",
    "    description=\"\"\"Write a well-structured, engaging,\n",
    "                   and technically accurate article\n",
    "                   on {topic}.\"\"\",\n",
    "    \n",
    "    agent=senior_technical_writer, \n",
    "    \n",
    "    \n",
    "    expected_output=\"\"\"A polished, detailed, and easy-to-read\n",
    "                       article on the given topic.\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa53ddd",
   "metadata": {},
   "source": [
    "## Create a Crew and Execute the Task\n",
    "\n",
    "This block creates a crew to manage the task and agents. It then kicks off the crew with the specified input and displays the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6593db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[senior_technical_writer],\n",
    "    tasks=[writing_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = crew.kickoff(inputs={\"topic\":\"AI Agents\"})\n",
    "\n",
    "# Display the response in Markdown format\n",
    "Markdown(response.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165ab92",
   "metadata": {},
   "source": [
    "## Save the Response to a File\n",
    "\n",
    "This block saves the raw response from the crew execution to a Markdown file for further use or documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19bf8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"build/output.md\", \"w\")\n",
    "f.write(response.raw)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906f832",
   "metadata": {},
   "source": [
    "# Define a file reader tool (OPENAI ONLY - DOES NOT WORK WITH OLLAMA MODELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5318d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import FileReadTool\n",
    "\n",
    "file_read_tool = FileReadTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0f53a",
   "metadata": {},
   "source": [
    "## Troubleshooting Note\n",
    "\n",
    "**Issue:** The original code was encountering an `IndexError` in the litellm/ollama integration when using CrewAI tools. The error occurred in the prompt template processing where `messages[msg_i]` was accessing an index out of range.\n",
    "\n",
    "**Root Cause:** This appears to be a compatibility issue between:\n",
    "- CrewAI's tool integration system\n",
    "- LiteLLM's Ollama prompt template processing\n",
    "- The FileReadTool parameter validation\n",
    "\n",
    "**Solution:** \n",
    "1. **Enabled debugging** with `litellm._turn_on_debug()` to get detailed error information\n",
    "2. **Removed the FileReadTool** from the agent to avoid the tool integration bug\n",
    "3. **Read file content directly** in Python and embedded it in the task description\n",
    "4. **Simplified the workflow** to avoid dynamic parameter passing\n",
    "\n",
    "This approach maintains the same functionality while working around the integration issue.\n",
    "\n",
    "**Results:**\n",
    "- This solution did not work either.  I was unable to get CrewAI FileReadTool or any custom specialized Tool Function to work with ollama based GenAI models.  The tool usage only worked for OpenAI for some reason."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35968303",
   "metadata": {},
   "source": [
    "## Define the Agent For Reading And Summarizing Files (OPENAI ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent\n",
    "\n",
    "summarizer_agent = Agent(\n",
    "    role=\"Senior Document Summarizer\",\n",
    "\n",
    "    goal=\"Extract and summarize key insights from provided files in 20 words or less.\",\n",
    "    backstory=\"\"\"You are an expert in document analysis, skilled at extracting \n",
    "                 key details, summarizing content, and identifying critical \n",
    "                 insights from structured and unstructured text.\"\"\",\n",
    "    llm=llm,\n",
    "    tools=[file_read_tool],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab376f92",
   "metadata": {},
   "source": [
    "## Create Reading and Analyzing File Task (OPENAI ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task\n",
    "\n",
    "summarizer_task = Task(\n",
    "    description=(\n",
    "        \"Use the FileReadTool to read the contents of {file_path}\"\n",
    "        \"and provide a summary in 20 words or less. \"\n",
    "        \"Ensure the summary captures the key insights \"\n",
    "        \"and main points from the document.\"\n",
    "    ),\n",
    "    agent=summarizer_agent,\n",
    "    tools=[file_read_tool],\n",
    "    expected_output=\"A concise 20-word summary of the key points from the file.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f91c54",
   "metadata": {},
   "source": [
    "## Assemble A File-Processing Crew Workflow (OPENAI ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae4fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew\n",
    "\n",
    "summarizer_crew = Crew(\n",
    "    agents=[summarizer_agent],\n",
    "    tasks=[summarizer_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the crew with the file input\n",
    "result = summarizer_crew.kickoff(inputs={\"file_path\": \"build/output.md\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65381976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the response in Markdown format\n",
    "from IPython.display import Markdown\n",
    "Markdown(result.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a2b2a",
   "metadata": {},
   "source": [
    "# Building multi-agent systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e71a80",
   "metadata": {},
   "source": [
    "## Define our Serper Dev tool\n",
    "\n",
    "The Serper Dev Tool is a utility designed to interact with search engines and retrieve relevant information programmatically. It is particularly useful for tasks that require real-time data or insights from the web, such as:\n",
    "\n",
    "1. Conducting research on specific topics.\n",
    "2. Gathering up-to-date information for decision-making.\n",
    "3. Enhancing the capabilities of agents by providing them with access to external data sources.\n",
    "\n",
    "### How It Can Be Used\n",
    "- **Integration with Agents**: The tool can be integrated into agents to enable them to fetch and process web-based information dynamically.\n",
    "- **Custom Queries**: Developers can define specific queries to retrieve targeted information, making it adaptable to various use cases.\n",
    "- **Real-Time Insights**: By leveraging the tool, agents can provide real-time insights and context, improving the quality and relevance of their outputs.\n",
    "\n",
    "This tool is ideal for scenarios where static data is insufficient, and dynamic, real-time information is required to achieve the desired outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66056688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import SerperDevTool\n",
    "\n",
    "serper_dev_tool = SerperDevTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225fb0f",
   "metadata": {},
   "source": [
    "## Define the Internet Researcher Agent and Task\n",
    "\n",
    "This block defines an `Internet Researcher` agent and a corresponding research task. \n",
    "- The agent is equipped with the `SerperDevTool` to perform web-based research. \n",
    "- The agent's role is to find the most relevant and recent information about a given topic, leveraging its expertise in navigating the internet and gathering reliable data. \n",
    "- The task specifies the use of the `SerperDevTool` to extract key insights from multiple sources and produce a detailed research report with references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf1cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task\n",
    "\n",
    "research_agent = Agent(\n",
    "    role=\"Internet Researcher\",\n",
    "    goal=\"Find the most relevant and recent information about a given topic.\",\n",
    "    backstory=\"\"\"You are a skilled researcher, adept at navigating the internet \n",
    "                 and gathering high-quality, reliable information.\"\"\",\n",
    "    tools=[serper_dev_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "research_task = Task(\n",
    "    description=\"\"\"Use the SerperDevTool to search for the \n",
    "                   most relevant and recent data about {topic}.\"\"\"\n",
    "                \"Extract the key insights from multiple sources.\",\n",
    "    agent=research_agent,\n",
    "    tools=[serper_dev_tool],\n",
    "    expected_output=\"A detailed research report with key insights and source references.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb651e7",
   "metadata": {},
   "source": [
    "## Define The Summarization Agent\n",
    "\n",
    "This agent is responsible for condensing the research into a concise and structured summary. The Summarization Agent ensures that the research findings are structured, easy to read, and clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_agent = Agent(\n",
    "    role=\"Content Summarizer\",\n",
    "    goal=\"Condense the key insights from research into a short and informative summary.\",\n",
    "    backstory=\"\"\"You are an expert in distilling complex information into concise, \n",
    "                 easy-to-read summaries.\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "summarization_task = Task(\n",
    "    description=\"Summarize the research report into a concise and informative paragraph. \"\n",
    "                \"Ensure clarity, coherence, and completeness.\",\n",
    "    agent=summarizer_agent,\n",
    "    expected_output=\"A well-structured summary with the most important insights.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f462264",
   "metadata": {},
   "source": [
    "## Define The Fact-Checking Agent\n",
    "\n",
    "The Fact-Checking Agent will cross-check all summarized information with credible sources:\n",
    "\n",
    "- The Fact-Checking Agent is responsible for validating the summarized information.\n",
    "- The Serper Dev Tool is used again to cross-check facts with external sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_checker_agent = Agent(\n",
    "    role=\"Fact-Checking Specialist\",\n",
    "    goal=\"Verify the accuracy of information and remove any misleading or false claims.\",\n",
    "    backstory=\"\"\"You are an investigative journalist with a knack for validating facts, \n",
    "                 ensuring that only accurate information is published.\"\"\",\n",
    "    tools=[serper_dev_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "fact_checking_task = Task(\n",
    "    description=\"Verify the summarized information for accuracy using the SerperDevTool. \"\n",
    "                \"Cross-check facts with reliable sources and correct any errors.\",\n",
    "    agent=fact_checker_agent,\n",
    "    tools=[serper_dev_tool],\n",
    "    expected_output=\"A fact-checked, verified summary of the research topic.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad6696",
   "metadata": {},
   "source": [
    "## Create Multi-Agent Crew Workflow\n",
    "\n",
    "- All three agents are grouped into a Crew, each assigned their specific task.\n",
    "- Tasks are executed sequentially in a structured workflow:  Research ‚Üí Summarization ‚Üí Fact-Checking.\n",
    "- The topic is dynamically provided at runtime, making the workflow flexible for any research topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process\n",
    "\n",
    "research_crew = Crew(\n",
    "    agents=[research_agent, summarizer_agent, fact_checker_agent],\n",
    "    tasks=[research_task, summarization_task, fact_checking_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab4e081",
   "metadata": {},
   "source": [
    "## Kickoff The Multi-Agent Crew Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = research_crew.kickoff(inputs={\"topic\": \"The impact of AI on job markets\"})\n",
    "\n",
    "# print(\"\\nFinal Verified Summary:\\n\", result)\n",
    "Markdown(result.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de290a",
   "metadata": {},
   "source": [
    "# Using YAML Based Agent and Workflow Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc0815",
   "metadata": {},
   "source": [
    "## Load YAML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a076333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "# Uncomment the following line to print the configuration\n",
    "# \n",
    "# from pprint import pprint\n",
    "# pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dead00b",
   "metadata": {},
   "source": [
    "## Convert Agent Definitions to use YAML Config Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = Agent(\n",
    "    role=config[\"agents\"][\"research_agent\"][\"role\"],\n",
    "    goal=config[\"agents\"][\"research_agent\"][\"goal\"],\n",
    "    backstory=config[\"agents\"][\"research_agent\"][\"backstory\"],\n",
    "    tools=[serper_dev_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "research_task = Task(\n",
    "    description=config[\"tasks\"][\"research_task\"][\"description\"],\n",
    "    agent=research_agent,\n",
    "    tools=[serper_dev_tool],\n",
    "    expected_output=config[\"tasks\"][\"research_task\"][\"expected_output\"]\n",
    ")\n",
    "\n",
    "summarization_agent = Agent(\n",
    "    role=config[\"agents\"][\"summarization_agent\"][\"role\"],\n",
    "    goal=config[\"agents\"][\"summarization_agent\"][\"goal\"],\n",
    "    backstory=config[\"agents\"][\"summarization_agent\"][\"backstory\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "fact_checker_agent = Agent(\n",
    "    role=config[\"agents\"][\"fact_checker_agent\"][\"role\"],\n",
    "    goal=config[\"agents\"][\"fact_checker_agent\"][\"goal\"],\n",
    "    backstory=config[\"agents\"][\"fact_checker_agent\"][\"backstory\"],\n",
    "    tools=[serper_dev_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "summarization_task = Task(\n",
    "    description=config[\"tasks\"][\"summarization_task\"][\"description\"],\n",
    "    agent=summarization_agent,\n",
    "    expected_output=config[\"tasks\"][\"summarization_task\"][\"expected_output\"],\n",
    ")\n",
    "\n",
    "fact_checking_task = Task(\n",
    "    description=config[\"tasks\"][\"fact_checking_task\"][\"description\"],\n",
    "    agent=fact_checker_agent,\n",
    "    tools=[serper_dev_tool],\n",
    "    expected_output=config[\"tasks\"][\"fact_checking_task\"][\"expected_output\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b037e",
   "metadata": {},
   "source": [
    "## Create Multi-Agent Crew Workflow\n",
    "\n",
    "- All three agents are grouped into a Crew, each assigned their specific task.\n",
    "- Tasks are executed sequentially in a structured workflow:  Research ‚Üí Summarization ‚Üí Fact-Checking.\n",
    "- The topic is dynamically provided at runtime, making the workflow flexible for any research topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process\n",
    "\n",
    "research_crew = Crew(\n",
    "    agents=[research_agent, summarizer_agent, fact_checker_agent],\n",
    "    tasks=[research_task, summarization_task, fact_checking_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = research_crew.kickoff(inputs={\"topic\": \"The impact of AI on job markets\"})\n",
    "print(\"\\nFinal Verified Summary:\\n\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
