{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d3890e2",
   "metadata": {},
   "source": [
    "# AI Agents Crash Course - Part 2 - Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411381fe",
   "metadata": {},
   "source": [
    "## Project Setup\n",
    "\n",
    "This notebook will guide you through setting up the project environment for using CrewAI. We will:\n",
    "\n",
    "1. Install the required Python modules.\n",
    "2. Set up a virtual environment.\n",
    "3. Verify the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd38de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you are not using devcontainers and want to set up a local environment\n",
    "# \n",
    "# # Step 1: Create and activate a virtual environment\n",
    "# #\n",
    "# %python3 -m venv venv\n",
    "# %source venv/bin/activate\n",
    "# \n",
    "# # Step 2: Install required Python modules\n",
    "# #\n",
    "# %pip install -r requirements.txt\n",
    "# \n",
    "# # Step 3: Verify installation\n",
    "# #\n",
    "# %pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc1c63",
   "metadata": {},
   "source": [
    "## Load Required Python Modules and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3773848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown\n",
    "from crewai import LLM, Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7227f889",
   "metadata": {},
   "source": [
    "## [Optional] Enable litellm debug logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91476bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment in order to enable litellm debugging for better error diagnostics\n",
    "# NOTE: You will have to restart the jupyter kernel to disable debug logging once it has been enabled.\n",
    "#\n",
    "# import litellm\n",
    "# litellm._turn_on_debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14be36ad",
   "metadata": {},
   "source": [
    "## Load Environment Variables and Configure LLM\n",
    "\n",
    "This block loads environment variables from the `.env` file, including the OpenAI API Key, which is required to authenticate with OpenAI's services. It then configures the `LLM` object to use OpenAI's GPT-4 model. Alternatively, you can uncomment the provided code to configure the `LLM` object to use Ollama with a local model, provided Ollama is installed and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f650db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# Note: In devcontainer, variables are already loaded by dotenv feature,\n",
    "# but load_dotenv() is safe and won't override existing environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Uncomment the code block below to use OpenAI with your API Key\n",
    "# \n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "# if not api_key:\n",
    "#     raise ValueError(\"OPENAI_API_KEY is not set in the .env file\")\n",
    "\n",
    "# Uncomment the code block below to use ollama\n",
    "# \n",
    "OLLAMA_API_BASE = os.getenv('OLLAMA_API_BASE')\n",
    "if not OLLAMA_API_BASE:\n",
    "    raise ValueError(\"OLLAMA_API_BASE is not set in the .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72d53b",
   "metadata": {},
   "source": [
    "## Configure LLM\n",
    "\n",
    "Configures the `LLM` object to use OpenAI's GPT-4 model. \n",
    "\n",
    "Alternatively, you can uncomment the provided code to configure the `LLM` object to use Ollama with a local model, provided Ollama is installed and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1df9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = LLM(\n",
    "#     model=\"gpt-4o\",  # Specify the OpenAI model you want to use\n",
    "#     api_key=api_key\n",
    "# )\n",
    "\n",
    "# Uncomment the code block below to use Ollama with your local model\n",
    "# Make sure to have Ollama installed and running\n",
    "# \n",
    "llm = LLM(\n",
    "    # model=\"ollama/llama3:latest\",\n",
    "    # model=\"ollama/llama3.2:1b\",\n",
    "    # model=\"ollama/deepseek-r1:latest\",\n",
    "    # model=\"ollama/gemma3:latest\",\n",
    "    model=\"ollama/gemma3n:latest\",\n",
    "    base_url=OLLAMA_API_BASE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a242a",
   "metadata": {},
   "source": [
    "## Verify LLM Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76cfd69",
   "metadata": {},
   "source": [
    "### Universal LLM Connection Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15858ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "def test_llm_connection():\n",
    "    \"\"\"Test LLM connection regardless of provider\"\"\"\n",
    "    \n",
    "    print(\"=== LLM Configuration Analysis ===\")\n",
    "    \n",
    "    # Analyze LLM configuration\n",
    "    model_name = getattr(llm, 'model', 'Unknown')\n",
    "    base_url = getattr(llm, 'base_url', None)\n",
    "    api_key_set = bool(getattr(llm, 'api_key', None))\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Base URL: {base_url if base_url else 'Default (provider-specific)'}\")\n",
    "    print(f\"API Key Set: {'Yes' if api_key_set else 'No'}\")\n",
    "    \n",
    "    # Determine provider type\n",
    "    provider = \"unknown\"\n",
    "    if \"ollama\" in model_name.lower():\n",
    "        provider = \"ollama\"\n",
    "    elif \"gpt\" in model_name.lower() or \"openai\" in model_name.lower():\n",
    "        provider = \"openai\"\n",
    "    elif \"claude\" in model_name.lower() or \"anthropic\" in model_name.lower():\n",
    "        provider = \"anthropic\"\n",
    "    elif \"gemini\" in model_name.lower() or \"google\" in model_name.lower():\n",
    "        provider = \"google\"\n",
    "    \n",
    "    print(f\"Detected Provider: {provider}\")\n",
    "    \n",
    "    # Provider-specific connection tests\n",
    "    print(f\"\\n=== {provider.title()} Connection Test ===\")\n",
    "    \n",
    "    if provider == \"ollama\" and base_url:\n",
    "        try:\n",
    "            # Test Ollama server availability\n",
    "            test_url = f\"{base_url}/api/tags\"\n",
    "            response = requests.get(test_url, timeout=5)\n",
    "            print(f\"Ollama Server Status: {response.status_code}\")\n",
    "            if response.status_code == 200:\n",
    "                models = response.json().get('models', [])\n",
    "                print(f\"Available Models: {len(models)} found\")\n",
    "                # Check if our specific model is available\n",
    "                model_available = any(model_name.replace('ollama/', '') in str(model) for model in models)\n",
    "                print(f\"Target Model Available: {'Yes' if model_available else 'No'}\")\n",
    "            else:\n",
    "                print(f\"Ollama server responded with status: {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Ollama server connection failed: {e}\")\n",
    "    \n",
    "    elif provider == \"openai\":\n",
    "        print(\"OpenAI connection test (API key validation happens during LLM call)\")\n",
    "        api_key_env = os.getenv('OPENAI_API_KEY')\n",
    "        print(f\"OPENAI_API_KEY environment variable: {'Set' if api_key_env else 'Not set'}\")\n",
    "    \n",
    "    elif provider == \"anthropic\":\n",
    "        print(\"Anthropic connection test\")\n",
    "        api_key_env = os.getenv('ANTHROPIC_API_KEY')\n",
    "        print(f\"ANTHROPIC_API_KEY environment variable: {'Set' if api_key_env else 'Not set'}\")\n",
    "    \n",
    "    elif provider == \"google\":\n",
    "        print(\"Google AI connection test\")\n",
    "        api_key_env = os.getenv('GOOGLE_API_KEY')\n",
    "        print(f\"GOOGLE_API_KEY environment variable: {'Set' if api_key_env else 'Not set'}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Generic provider - will test with LLM call only\")\n",
    "    \n",
    "    # Universal LLM functionality test\n",
    "    print(f\"\\n=== LLM Functionality Test ===\")\n",
    "    try:\n",
    "        test_response = llm.call([{\"role\": \"user\", \"content\": \"Respond with exactly: 'Test successful'\"}])\n",
    "        print(\"‚úÖ LLM call successful!\")\n",
    "        print(f\"Response type: {type(test_response)}\")\n",
    "        \n",
    "        # Try to extract response content\n",
    "        if hasattr(test_response, 'content'):\n",
    "            print(f\"Response content: {test_response.content[:100]}...\")\n",
    "        elif isinstance(test_response, str):\n",
    "            print(f\"Response: {test_response[:100]}...\")\n",
    "        else:\n",
    "            print(f\"Response: {str(test_response)[:100]}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LLM call failed: {e}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        \n",
    "        # Provide specific troubleshooting tips based on error\n",
    "        error_str = str(e).lower()\n",
    "        if \"connection\" in error_str or \"timeout\" in error_str:\n",
    "            print(\"üí° Tip: Check network connection and base_url configuration\")\n",
    "        elif \"api_key\" in error_str or \"authentication\" in error_str or \"unauthorized\" in error_str:\n",
    "            print(\"üí° Tip: Check API key configuration and permissions\")\n",
    "        elif \"model\" in error_str or \"not found\" in error_str:\n",
    "            print(\"üí° Tip: Verify model name and availability\")\n",
    "\n",
    "# Run the comprehensive test\n",
    "test_llm_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4fc76c",
   "metadata": {},
   "source": [
    "### Environment Variables Check for All LLM Providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dee670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_environment_variables():\n",
    "    \"\"\"Check environment variables for all major LLM providers\"\"\"\n",
    "    \n",
    "    print(\"=== Environment Variables Status ===\")\n",
    "    \n",
    "    # Common LLM provider environment variables\n",
    "    env_vars = {\n",
    "        \"OpenAI\": [\"OPENAI_API_KEY\", \"OPENAI_BASE_URL\"],\n",
    "        \"Anthropic\": [\"ANTHROPIC_API_KEY\"],\n",
    "        \"Google\": [\"GOOGLE_API_KEY\", \"GOOGLE_APPLICATION_CREDENTIALS\"],\n",
    "        \"Cohere\": [\"COHERE_API_KEY\"],\n",
    "        \"Hugging Face\": [\"HUGGINGFACE_API_KEY\", \"HF_TOKEN\"],\n",
    "        \"Ollama\": [\"OLLAMA_API_BASE\", \"OLLAMA_HOST\"],\n",
    "        \"Azure OpenAI\": [\"AZURE_OPENAI_API_KEY\", \"AZURE_OPENAI_ENDPOINT\"],\n",
    "        \"AWS Bedrock\": [\"AWS_ACCESS_KEY_ID\", \"AWS_SECRET_ACCESS_KEY\", \"AWS_REGION\"],\n",
    "        \"Together AI\": [\"TOGETHER_API_KEY\"],\n",
    "        \"Replicate\": [\"REPLICATE_API_TOKEN\"],\n",
    "        \"Perplexity\": [\"PERPLEXITYAI_API_KEY\"],\n",
    "        \"Groq\": [\"GROQ_API_KEY\"]\n",
    "    }\n",
    "    \n",
    "    found_providers = []\n",
    "    \n",
    "    for provider, vars_list in env_vars.items():\n",
    "        provider_vars = {}\n",
    "        has_any_var = False\n",
    "        \n",
    "        for var in vars_list:\n",
    "            value = os.getenv(var)\n",
    "            if value:\n",
    "                provider_vars[var] = \"‚úÖ Set\"\n",
    "                has_any_var = True\n",
    "            else:\n",
    "                provider_vars[var] = \"‚ùå Not set\"\n",
    "        \n",
    "        if has_any_var:\n",
    "            found_providers.append(provider)\n",
    "            print(f\"\\n{provider}:\")\n",
    "            for var, status in provider_vars.items():\n",
    "                print(f\"  {var}: {status}\")\n",
    "    \n",
    "    if not found_providers:\n",
    "        print(\"No LLM provider environment variables found.\")\n",
    "        print(\"Make sure to set the appropriate API keys for your chosen provider.\")\n",
    "    else:\n",
    "        print(f\"\\nConfigured providers: {', '.join(found_providers)}\")\n",
    "\n",
    "# Run environment check\n",
    "check_environment_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961b762",
   "metadata": {},
   "source": [
    "## Building Crew Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05b00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
