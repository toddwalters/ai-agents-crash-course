{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d3890e2",
   "metadata": {},
   "source": [
    "# AI Agents Crash Course - Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411381fe",
   "metadata": {},
   "source": [
    "# Project Setup\n",
    "\n",
    "This notebook will guide you through setting up the project environment for using CrewAI. We will:\n",
    "\n",
    "1. Install the required Python modules.\n",
    "2. Set up a virtual environment.\n",
    "3. Verify the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd38de7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment if you are not using devcontainers and want to set up a local environment\n",
    "# \n",
    "# # Step 1: Create and activate a virtual environment\n",
    "# #\n",
    "# %python3 -m venv venv\n",
    "# %source venv/bin/activate\n",
    "# \n",
    "# # Step 2: Install required Python modules\n",
    "# #\n",
    "# %pip install -r requirements.txt\n",
    "# \n",
    "# # Step 3: Verify installation\n",
    "# #\n",
    "# %pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc1c63",
   "metadata": {},
   "source": [
    "# Load Required Python Modules and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3773848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown\n",
    "from crewai import LLM, Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53830656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LiteLLM Debug Control\n",
    "# Run this cell to easily enable or disable litellm debugging\n",
    "import litellm\n",
    "\n",
    "def enable_litellm_debug():\n",
    "    \"\"\"Enable litellm debugging for detailed error diagnostics\"\"\"\n",
    "    litellm._turn_on_debug()\n",
    "    print(\"âœ… LiteLLM debugging ENABLED\")\n",
    "    print(\"   - You will see detailed logs for LLM calls\")\n",
    "    print(\"   - Useful for troubleshooting connection and integration issues\")\n",
    "\n",
    "def disable_litellm_debug():\n",
    "    \"\"\"Disable litellm debugging to reduce verbose output\"\"\"\n",
    "    litellm._turn_off_debug()\n",
    "    print(\"ðŸ”‡ LiteLLM debugging DISABLED\")\n",
    "    print(\"   - Reduced log output for cleaner execution\")\n",
    "\n",
    "def check_litellm_debug_status():\n",
    "    \"\"\"Check if litellm debugging is currently enabled\"\"\"\n",
    "    # litellm doesn't have a direct way to check debug status,\n",
    "    # so we'll check the logging level as a proxy\n",
    "    import logging\n",
    "    logger = logging.getLogger(\"litellm\")\n",
    "    if logger.level <= logging.DEBUG:\n",
    "        print(\"ðŸ” LiteLLM debugging appears to be ENABLED\")\n",
    "    else:\n",
    "        print(\"ðŸ”‡ LiteLLM debugging appears to be DISABLED\")\n",
    "\n",
    "# Uncomment one of the following lines to control debugging:\n",
    "# enable_litellm_debug()    # Enable debugging\n",
    "# disable_litellm_debug()   # Disable debugging\n",
    "check_litellm_debug_status()  # Check current status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0371efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Debug Control - Run any of these cells for immediate control:\n",
    "\n",
    "# ðŸŸ¢ ENABLE DEBUGGING (run this cell)\n",
    "# enable_litellm_debug()\n",
    "\n",
    "# ðŸ”´ DISABLE DEBUGGING (run this cell)  \n",
    "# disable_litellm_debug()\n",
    "\n",
    "# ðŸ” CHECK STATUS (run this cell)\n",
    "# check_litellm_debug_status()\n",
    "\n",
    "print(\"ðŸ’¡ Tip: Uncomment and run the function you need above, or use the functions from the previous cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14be36ad",
   "metadata": {},
   "source": [
    "# Load Environment Variables and Configure LLM\n",
    "\n",
    "This block loads environment variables from the `.env` file, including the OpenAI API Key, which is required to authenticate with OpenAI's services. It then configures the `LLM` object to use OpenAI's GPT-4 model. Alternatively, you can uncomment the provided code to configure the `LLM` object to use Ollama with a local model, provided Ollama is installed and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f650db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# Note: In devcontainer, variables are already loaded by dotenv feature,\n",
    "# but load_dotenv() is safe and won't override existing environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Uncomment the code block below to use OpenAI with your API Key\n",
    "# \n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "# if not api_key:\n",
    "#     raise ValueError(\"OPENAI_API_KEY is not set in the .env file\")\n",
    "\n",
    "# Uncomment the code block below to use ollama\n",
    "# \n",
    "OLLAMA_API_BASE = os.getenv('OLLAMA_API_BASE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d72d53b",
   "metadata": {},
   "source": [
    "# Configure LLM\n",
    "\n",
    "Configures the `LLM` object to use OpenAI's GPT-4 model. \n",
    "\n",
    "Alternatively, you can uncomment the provided code to configure the `LLM` object to use Ollama with a local model, provided Ollama is installed and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1df9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = LLM(\n",
    "#     model=\"gpt-4o\",  # Specify the OpenAI model you want to use\n",
    "#     api_key=api_key\n",
    "# )\n",
    "\n",
    "# Uncomment the code block below to use Ollama with your local model\n",
    "# Make sure to have Ollama installed and running\n",
    "# \n",
    "llm = LLM(\n",
    "    model=\"ollama/openhermes:latest\",\n",
    "    base_url=OLLAMA_API_BASE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
