{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971de429",
   "metadata": {},
   "source": [
    "# Project Setup\n",
    "\n",
    "This notebook will guide you through setting up the project environment for using CrewAI. We will:\n",
    "\n",
    "1. Install the required Python modules.\n",
    "2. Set up a virtual environment.\n",
    "3. Verify the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61fcc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment if you are not using devcontainers and want to set up a local environment\n",
    "# \n",
    "# # Step 1: Create and activate a virtual environment\n",
    "# #\n",
    "# %python3 -m venv venv\n",
    "# %source venv/bin/activate\n",
    "# \n",
    "# # Step 2: Install required Python modules\n",
    "# #\n",
    "# %pip install -r requirements.txt\n",
    "# \n",
    "# # Step 3: Verify installation\n",
    "# #\n",
    "# %pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f46cb",
   "metadata": {},
   "source": [
    "# Load Required Python Modules and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69db235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown\n",
    "from crewai import LLM, Agent, Task, Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a3372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment in order to enable litellm debugging for better error diagnostics\n",
    "#\n",
    "import litellm\n",
    "litellm._turn_on_debug()\n",
    "print(\"✅ LiteLLM debugging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29096e08",
   "metadata": {},
   "source": [
    "# Load Environment Variables and Configure LLM\n",
    "\n",
    "This block loads environment variables from the `.env` file, including the OpenAI API Key, which is required to authenticate with OpenAI's services. It then configures the `LLM` object to use OpenAI's GPT-4 model. Alternatively, you can uncomment the provided code to configure the `LLM` object to use Ollama with a local model, provided Ollama is installed and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c357710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "# Note: In devcontainer, variables are already loaded by dotenv feature,\n",
    "# but load_dotenv() is safe and won't override existing environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Uncomment the code block below to use OpenAI with your API Key\n",
    "# \n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "# if not api_key:\n",
    "#     raise ValueError(\"OPENAI_API_KEY is not set in the .env file\")\n",
    "\n",
    "# Uncomment the code block below to use ollama\n",
    "# \n",
    "OLLAMA_API_BASE = os.getenv('OLLAMA_API_BASE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae28f8a",
   "metadata": {},
   "source": [
    "# Configure LLM\n",
    "\n",
    "Configures the `LLM` object to use OpenAI's GPT-4 model. \n",
    "\n",
    "Alternatively, you can uncomment the provided code to configure the `LLM` object to use Ollama with a local model, provided Ollama is installed and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34920e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = LLM(\n",
    "#     model=\"gpt-4o\",  # Specify the OpenAI model you want to use\n",
    "#     api_key=api_key\n",
    "# )\n",
    "\n",
    "# Uncomment the code block below to use Ollama with your local model\n",
    "# Make sure to have Ollama installed and running\n",
    "# \n",
    "llm = LLM(\n",
    "    model=\"ollama/gemma3n:latest\",\n",
    "    base_url=OLLAMA_API_BASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae2390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test ollam connectivity\n",
    "# \n",
    "import requests\n",
    "\n",
    "# Debug: Check environment variables and test Ollama connection\n",
    "# \n",
    "print(\"=== Environment Variables Debug ===\")\n",
    "print(f\"OLLAMA_API_BASE: {OLLAMA_API_BASE}\")\n",
    "test_url = f\"{OLLAMA_API_BASE}/api/tags\"\n",
    "\n",
    "# Test connection to your Ollama server\n",
    "# \n",
    "try:\n",
    "    response = requests.get(test_url, timeout=5)\n",
    "    print(f\"\\n=== Ollama Connection Test ===\")\n",
    "    print(f\"URL: {test_url}\")\n",
    "    print(f\"Status: {response.status_code}\")\n",
    "    print(f\"Response: {response.json()}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")\n",
    "\n",
    "# Debug: Check what base_url is actually being used\n",
    "# \n",
    "print(f\"\\n=== CrewAI LLM Connection Test ===\")\n",
    "# print(f\"ollama_base_url from env: {OLLAMA_API_BASE}\")\n",
    "print(f\"LLM base_url: {llm.base_url}\")\n",
    "print(f\"LLM model: {llm.model}\")\n",
    "\n",
    "# Test a simple LLM call\n",
    "try:\n",
    "    test_response = llm.call([{\"role\": \"user\", \"content\": \"Say hello!\"}])\n",
    "    print(\"✅ LLM test successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ LLM test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3cce4d",
   "metadata": {},
   "source": [
    "# Single Agent Single Tool Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328a98aa",
   "metadata": {},
   "source": [
    "## Define Agents\n",
    "\n",
    "This block defines multiple agents with specific roles, goals, and backstories. Each agent is configured to use the LLM defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3d81170",
   "metadata": {},
   "outputs": [],
   "source": [
    "senior_technical_writer = Agent(\n",
    "    role=\"Senior Technical Writer\",\n",
    "    \n",
    "    goal=\"\"\"Craft clear, engaging, and well-structured\n",
    "            technical content based on research findings\"\"\",\n",
    "    \n",
    "    backstory=\"\"\"You are an experienced technical writer\n",
    "                with expertise in simplifying complex\n",
    "                concepts, structuring content for readability,\n",
    "                and ensuring accuracy in documentation.\"\"\",\n",
    "                \n",
    "    llm=llm,\n",
    "                \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "research_analyst = Agent(\n",
    "    role=\"Senior Research Analyst\",\n",
    "    goal=\"\"\"Find, analyze, and summarize information \n",
    "            from various sources to support technical \n",
    "            and business-related inquiries.\"\"\",\n",
    "    backstory=\"\"\"You are a skilled research analyst with expertise \n",
    "                in gathering accurate data, identifying key trends, \n",
    "                and presenting insights in a structured manner.\"\"\",\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "code_reviewer = Agent(\n",
    "    role=\"Senior Code Reviewer\",\n",
    "    goal=\"\"\"Review code for bugs, inefficiencies, and \n",
    "            security vulnerabilities while ensuring adherence \n",
    "            to best coding practices.\"\"\",\n",
    "    backstory=\"\"\"You are a seasoned software engineer with years of \n",
    "                experience in writing, reviewing, and optimizing \n",
    "                production-level code in multiple programming languages.\"\"\",\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "legal_reviewer = Agent(\n",
    "    role=\"Legal Document Expert Reviewer\",\n",
    "    goal=\"\"\"Review contracts and legal documents to \n",
    "            ensure compliance with applicable laws and \n",
    "            highlight potential risks.\"\"\",\n",
    "    backstory=\"\"\"You are a legal expert with deep knowledge \n",
    "                of contract law, regulatory frameworks, \n",
    "                and risk mitigation strategies.\"\"\",\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b129e270",
   "metadata": {},
   "source": [
    "## Define a Writing Task\n",
    "\n",
    "This block defines a writing task for the Senior Technical Writer agent. The task includes a description, the agent responsible, and the expected output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c611c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writing_task = Task(\n",
    "    description=\"\"\"Write a well-structured, engaging,\n",
    "                   and technically accurate article\n",
    "                   on {topic}.\"\"\",\n",
    "    \n",
    "    agent=senior_technical_writer, \n",
    "    \n",
    "    \n",
    "    expected_output=\"\"\"A polished, detailed, and easy-to-read\n",
    "                       article on the given topic.\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa53ddd",
   "metadata": {},
   "source": [
    "## Create a Crew and Execute the Task\n",
    "\n",
    "This block creates a crew to manage the task and agents. It then kicks off the crew with the specified input and displays the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6593db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "    agents=[senior_technical_writer],\n",
    "    tasks=[writing_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "response = crew.kickoff(inputs={\"topic\":\"AI Agents\"})\n",
    "\n",
    "# Display the response in Markdown format\n",
    "Markdown(response.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d165ab92",
   "metadata": {},
   "source": [
    "## Save the Response to a File\n",
    "\n",
    "This block saves the raw response from the crew execution to a Markdown file for further use or documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d19bf8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"build/output.md\", \"w\")\n",
    "f.write(response.raw)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906f832",
   "metadata": {},
   "source": [
    "## Define a file reader tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d85bd542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Enable litellm debugging for better error diagnostics\n",
    "import litellm\n",
    "litellm._turn_on_debug()\n",
    "print(\"✅ LiteLLM debugging enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0f53a",
   "metadata": {},
   "source": [
    "## Troubleshooting Note\n",
    "\n",
    "**Issue:** The original code was encountering an `IndexError` in the litellm/ollama integration when using CrewAI tools. The error occurred in the prompt template processing where `messages[msg_i]` was accessing an index out of range.\n",
    "\n",
    "**Root Cause:** This appears to be a compatibility issue between:\n",
    "- CrewAI's tool integration system\n",
    "- LiteLLM's Ollama prompt template processing\n",
    "- The FileReadTool parameter validation\n",
    "\n",
    "**Solution:** \n",
    "1. **Enabled debugging** with `litellm._turn_on_debug()` to get detailed error information\n",
    "2. **Removed the FileReadTool** from the agent to avoid the tool integration bug\n",
    "3. **Read file content directly** in Python and embedded it in the task description\n",
    "4. **Simplified the workflow** to avoid dynamic parameter passing\n",
    "\n",
    "This approach maintains the same functionality while working around the integration issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28888cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.11/site-packages/pydantic/fields.py:1093: PydanticDeprecatedSince20: Using extra keyword arguments on `Field` is deprecated and will be removed. Use `json_schema_extra` instead. (Extra keys: 'required'). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from crewai_tools import FileReadTool\n",
    "\n",
    "file_read_tool = FileReadTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb57c041",
   "metadata": {},
   "source": [
    "## Define the Agent For Reading And Summarizing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8784ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent\n",
    "\n",
    "summarizer_agent = Agent(\n",
    "    role=\"Senior Document Summarizer\",\n",
    "    goal=\"Extract and summarize key insights from provided content in 20 words or less.\",\n",
    "    backstory=\"\"\"You are an expert in document analysis, skilled at extracting \n",
    "                 key details, summarizing content, and identifying critical \n",
    "                 insights from structured and unstructured text.\"\"\",\n",
    "    llm=llm,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd16bed",
   "metadata": {},
   "source": [
    "## Create Reading and Analyzing File Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df0275b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Task\n",
    "\n",
    "# Read the file content directly to avoid tool integration issues\n",
    "with open(\"build/output.md\", \"r\") as file:\n",
    "    file_content = file.read()\n",
    "\n",
    "summarizer_task = Task(\n",
    "    description=f\"\"\"\n",
    "    Analyze the following document content and provide a summary in exactly 20 words or less. \n",
    "    Focus on the key insights and main points from the document.\n",
    "    \n",
    "    Document content:\n",
    "    {file_content}\n",
    "    \"\"\",\n",
    "    agent=summarizer_agent,\n",
    "    expected_output=\"A concise 20-word summary of the key points from the document.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b1df3f",
   "metadata": {},
   "source": [
    "## Assemble A File-Processing Crew Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew\n",
    "\n",
    "summarizer_crew = Crew(\n",
    "    agents=[summarizer_agent],\n",
    "    tasks=[summarizer_task],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the crew without inputs since content is embedded in task\n",
    "result = summarizer_crew.kickoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06e469cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "AI Agents are autonomous software entities perceiving, reasoning, acting, and learning to automate tasks across industries, facing challenges in safety, ethics, and scalability."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the response in Markdown format\n",
    "from IPython.display import Markdown\n",
    "Markdown(result.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bd6917",
   "metadata": {},
   "source": [
    "# Alternative: Using FileReadTool with OpenAI\n",
    "\n",
    "The following section demonstrates the original approach using the FileReadTool, which works properly with OpenAI but has compatibility issues with the current litellm/ollama setup. \n",
    "\n",
    "**Note:** To use this section, you need to:\n",
    "1. Set up an OpenAI API key in your environment\n",
    "2. Switch the LLM configuration to use OpenAI instead of Ollama\n",
    "3. Uncomment and run the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090519de",
   "metadata": {},
   "source": [
    "## Configure OpenAI LLM for FileReadTool Example\n",
    "\n",
    "First, configure the LLM to use OpenAI instead of Ollama for proper tool integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb14d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to use OpenAI LLM for FileReadTool example\n",
    "# Make sure you have OPENAI_API_KEY set in your environment\n",
    "#\n",
    "# import os\n",
    "# from crewai import LLM\n",
    "# \n",
    "# # Get OpenAI API key from environment\n",
    "# api_key = os.getenv('OPENAI_API_KEY')\n",
    "# if not api_key:\n",
    "#     raise ValueError(\"OPENAI_API_KEY is not set in the environment\")\n",
    "# \n",
    "# # Configure LLM for OpenAI\n",
    "# openai_llm = LLM(\n",
    "#     model=\"gpt-4o-mini\",  # Use a cost-effective model\n",
    "#     api_key=api_key\n",
    "# )\n",
    "# \n",
    "# print(\"✅ OpenAI LLM configured for FileReadTool example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5832d1",
   "metadata": {},
   "source": [
    "## Define FileReadTool and Agent (Original Approach)\n",
    "\n",
    "This is the original approach using the FileReadTool that works with OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f8c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to use the original FileReadTool approach with OpenAI\n",
    "#\n",
    "# from crewai_tools import FileReadTool\n",
    "# from crewai import Agent\n",
    "# \n",
    "# # Create the FileReadTool\n",
    "# file_read_tool_openai = FileReadTool()\n",
    "# \n",
    "# # Define the agent with FileReadTool (works with OpenAI)\n",
    "# summarizer_agent_openai = Agent(\n",
    "#     role=\"Senior Document Summarizer\",\n",
    "#     goal=\"Extract and summarize key insights from provided files in 20 words or less.\",\n",
    "#     backstory=\"\"\"You are an expert in document analysis, skilled at extracting \n",
    "#                  key details, summarizing content, and identifying critical \n",
    "#                  insights from structured and unstructured text.\"\"\",\n",
    "#     llm=openai_llm,  # Use OpenAI LLM instead of Ollama\n",
    "#     tools=[file_read_tool_openai],  # Include the FileReadTool\n",
    "#     verbose=True\n",
    "# )\n",
    "# \n",
    "# print(\"✅ FileReadTool agent configured for OpenAI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d23d39",
   "metadata": {},
   "source": [
    "## Define Task with FileReadTool (Original Approach)\n",
    "\n",
    "This task uses the FileReadTool to dynamically read files based on input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07dd2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to use the original task with FileReadTool\n",
    "#\n",
    "# from crewai import Task\n",
    "# \n",
    "# # Original task definition using FileReadTool\n",
    "# summarizer_task_openai = Task(\n",
    "#     description=(\n",
    "#         \"Use the FileReadTool to read the contents of {file_path} \"\n",
    "#         \"and provide a summary in 20 words or less. \"\n",
    "#         \"Ensure the summary captures the key insights \"\n",
    "#         \"and main points from the document.\"\n",
    "#     ),\n",
    "#     agent=summarizer_agent_openai,\n",
    "#     tools=[file_read_tool_openai],\n",
    "#     expected_output=\"A concise 20-word summary of the key points from the file.\",\n",
    "# )\n",
    "# \n",
    "# print(\"✅ FileReadTool task configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47e100",
   "metadata": {},
   "source": [
    "## Execute Crew with FileReadTool (Original Approach)\n",
    "\n",
    "This demonstrates the original workflow using dynamic file input with the FileReadTool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d9a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to execute the original FileReadTool approach\n",
    "#\n",
    "# from crewai import Crew\n",
    "# \n",
    "# # Create crew with FileReadTool agent\n",
    "# summarizer_crew_openai = Crew(\n",
    "#     agents=[summarizer_agent_openai],\n",
    "#     tasks=[summarizer_task_openai],\n",
    "#     verbose=True\n",
    "# )\n",
    "# \n",
    "# # Execute with dynamic file input (original approach)\n",
    "# result_openai = summarizer_crew_openai.kickoff(inputs={\"file_path\": \"build/output.md\"})\n",
    "# \n",
    "# # Display the result\n",
    "# from IPython.display import Markdown\n",
    "# print(\"📝 FileReadTool Result with OpenAI:\")\n",
    "# Markdown(result_openai.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b2a995",
   "metadata": {},
   "source": [
    "## Comparison: Tool vs Non-Tool Approaches\n",
    "\n",
    "### FileReadTool Approach (OpenAI Compatible)\n",
    "**Advantages:**\n",
    "- Dynamic file reading based on input parameters\n",
    "- Proper tool integration and validation\n",
    "- More flexible for different file paths\n",
    "- Standard CrewAI tool workflow\n",
    "\n",
    "**Requirements:**\n",
    "- OpenAI API key and credits\n",
    "- Compatible LLM provider (OpenAI, Anthropic, etc.)\n",
    "\n",
    "### Direct File Reading Approach (Ollama Compatible)\n",
    "**Advantages:**\n",
    "- Works with local Ollama models (no API costs)\n",
    "- Avoids tool integration compatibility issues\n",
    "- Simpler debugging and troubleshooting\n",
    "- Faster execution (no tool overhead)\n",
    "\n",
    "**Limitations:**\n",
    "- File path must be known at task creation time\n",
    "- Less flexible for dynamic file operations\n",
    "- Requires manual file handling\n",
    "\n",
    "### When to Use Each Approach\n",
    "\n",
    "**Use FileReadTool when:**\n",
    "- You have access to OpenAI or other compatible APIs\n",
    "- You need dynamic file reading capabilities\n",
    "- You want to follow standard CrewAI tool patterns\n",
    "- You're building production systems with proper tool validation\n",
    "\n",
    "**Use Direct File Reading when:**\n",
    "- You're using Ollama or other local models\n",
    "- You encounter tool integration issues\n",
    "- You need faster, simpler file processing\n",
    "- File paths are known at development time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a2b2a",
   "metadata": {},
   "source": [
    "# Building multi-agent systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e71a80",
   "metadata": {},
   "source": [
    "## Define our Serper Dev tool\n",
    "\n",
    "The Serper Dev Tool is a utility designed to interact with search engines and retrieve relevant information programmatically. It is particularly useful for tasks that require real-time data or insights from the web, such as:\n",
    "\n",
    "1. Conducting research on specific topics.\n",
    "2. Gathering up-to-date information for decision-making.\n",
    "3. Enhancing the capabilities of agents by providing them with access to external data sources.\n",
    "\n",
    "### How It Can Be Used\n",
    "- **Integration with Agents**: The tool can be integrated into agents to enable them to fetch and process web-based information dynamically.\n",
    "- **Custom Queries**: Developers can define specific queries to retrieve targeted information, making it adaptable to various use cases.\n",
    "- **Real-Time Insights**: By leveraging the tool, agents can provide real-time insights and context, improving the quality and relevance of their outputs.\n",
    "\n",
    "This tool is ideal for scenarios where static data is insufficient, and dynamic, real-time information is required to achieve the desired outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66056688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai_tools import SerperDevTool\n",
    "\n",
    "serper_dev_tool = SerperDevTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225fb0f",
   "metadata": {},
   "source": [
    "## Define the Internet Researcher Agent and Task\n",
    "\n",
    "This block defines an `Internet Researcher` agent and a corresponding research task. \n",
    "- The agent is equipped with the `SerperDevTool` to perform web-based research. \n",
    "- The agent's role is to find the most relevant and recent information about a given topic, leveraging its expertise in navigating the internet and gathering reliable data. \n",
    "- The task specifies the use of the `SerperDevTool` to extract key insights from multiple sources and produce a detailed research report with references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf1cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task\n",
    "\n",
    "research_agent = Agent(\n",
    "    role=\"Internet Researcher\",\n",
    "    goal=\"Find the most relevant and recent information about a given topic.\",\n",
    "    backstory=\"\"\"You are a skilled researcher, adept at navigating the internet \n",
    "                 and gathering high-quality, reliable information.\"\"\",\n",
    "    tools=[serper_dev_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "research_task = Task(\n",
    "    description=\"\"\"Use the SerperDevTool to search for the \n",
    "                   most relevant and recent data about {topic}.\"\"\"\n",
    "                \"Extract the key insights from multiple sources.\",\n",
    "    agent=research_agent,\n",
    "    tools=[serper_dev_tool],\n",
    "    expected_output=\"A detailed research report with key insights and source references.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb651e7",
   "metadata": {},
   "source": [
    "## Define The Summarization Agent\n",
    "\n",
    "This agent is responsible for condensing the research into a concise and structured summary. The Summarization Agent ensures that the research findings are structured, easy to read, and clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_agent = Agent(\n",
    "    role=\"Content Summarizer\",\n",
    "    goal=\"Condense the key insights from research into a short and informative summary.\",\n",
    "    backstory=\"\"\"You are an expert in distilling complex information into concise, \n",
    "                 easy-to-read summaries.\"\"\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "summarization_task = Task(\n",
    "    description=\"Summarize the research report into a concise and informative paragraph. \"\n",
    "                \"Ensure clarity, coherence, and completeness.\",\n",
    "    agent=summarizer_agent,\n",
    "    expected_output=\"A well-structured summary with the most important insights.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f462264",
   "metadata": {},
   "source": [
    "## Define The Fact-Checking Agent\n",
    "\n",
    "The Fact-Checking Agent will cross-check all summarized information with credible sources:\n",
    "\n",
    "- The Fact-Checking Agent is responsible for validating the summarized information.\n",
    "- The Serper Dev Tool is used again to cross-check facts with external sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_checker_agent = Agent(\n",
    "    role=\"Fact-Checking Specialist\",\n",
    "    goal=\"Verify the accuracy of information and remove any misleading or false claims.\",\n",
    "    backstory=\"\"\"You are an investigative journalist with a knack for validating facts, \n",
    "                 ensuring that only accurate information is published.\"\"\",\n",
    "    tools=[serper_dev_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "fact_checking_task = Task(\n",
    "    description=\"Verify the summarized information for accuracy using the SerperDevTool. \"\n",
    "                \"Cross-check facts with reliable sources and correct any errors.\",\n",
    "    agent=fact_checker_agent,\n",
    "    tools=[serper_dev_tool],\n",
    "    expected_output=\"A fact-checked, verified summary of the research topic.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad6696",
   "metadata": {},
   "source": [
    "## Create Multi-Agent Crew Workflow\n",
    "\n",
    "- All three agents are grouped into a Crew, each assigned their specific task.\n",
    "- Tasks are executed sequentially in a structured workflow:  Research → Summarization → Fact-Checking.\n",
    "- The topic is dynamically provided at runtime, making the workflow flexible for any research topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8995d029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process\n",
    "\n",
    "research_crew = Crew(\n",
    "    agents=[research_agent, summarizer_agent, fact_checker_agent],\n",
    "    tasks=[research_task, summarization_task, fact_checking_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab4e081",
   "metadata": {},
   "source": [
    "## Kickoff The Multi-Agent Crew Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b87cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = research_crew.kickoff(inputs={\"topic\": \"The impact of AI on job markets\"})\n",
    "\n",
    "# print(\"\\nFinal Verified Summary:\\n\", result)\n",
    "Markdown(result.raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de290a",
   "metadata": {},
   "source": [
    "# Using YAML Based Agent and Workflow Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc0815",
   "metadata": {},
   "source": [
    "## Load YAML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a076333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "# Uncomment the following line to print the configuration\n",
    "# \n",
    "# from pprint import pprint\n",
    "# pprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dead00b",
   "metadata": {},
   "source": [
    "## Convert Agent Definitions to use YAML Config Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763c4eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_agent = Agent(\n",
    "    role=config[\"agents\"][\"research_agent\"][\"role\"],\n",
    "    goal=config[\"agents\"][\"research_agent\"][\"goal\"],\n",
    "    backstory=config[\"agents\"][\"research_agent\"][\"backstory\"],\n",
    "    tools=[serper_dev_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "research_task = Task(\n",
    "    description=config[\"tasks\"][\"research_task\"][\"description\"],\n",
    "    agent=research_agent,\n",
    "    tools=[serper_dev_tool],\n",
    "    expected_output=config[\"tasks\"][\"research_task\"][\"expected_output\"]\n",
    ")\n",
    "\n",
    "summarization_agent = Agent(\n",
    "    role=config[\"agents\"][\"summarization_agent\"][\"role\"],\n",
    "    goal=config[\"agents\"][\"summarization_agent\"][\"goal\"],\n",
    "    backstory=config[\"agents\"][\"summarization_agent\"][\"backstory\"],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "fact_checker_agent = Agent(\n",
    "    role=config[\"agents\"][\"fact_checker_agent\"][\"role\"],\n",
    "    goal=config[\"agents\"][\"fact_checker_agent\"][\"goal\"],\n",
    "    backstory=config[\"agents\"][\"fact_checker_agent\"][\"backstory\"],\n",
    "    tools=[serper_dev_tool],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "summarization_task = Task(\n",
    "    description=config[\"tasks\"][\"summarization_task\"][\"description\"],\n",
    "    agent=summarization_agent,\n",
    "    expected_output=config[\"tasks\"][\"summarization_task\"][\"expected_output\"],\n",
    ")\n",
    "\n",
    "fact_checking_task = Task(\n",
    "    description=config[\"tasks\"][\"fact_checking_task\"][\"description\"],\n",
    "    agent=fact_checker_agent,\n",
    "    tools=[serper_dev_tool],\n",
    "    expected_output=config[\"tasks\"][\"fact_checking_task\"][\"expected_output\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b037e",
   "metadata": {},
   "source": [
    "## Create Multi-Agent Crew Workflow\n",
    "\n",
    "- All three agents are grouped into a Crew, each assigned their specific task.\n",
    "- Tasks are executed sequentially in a structured workflow:  Research → Summarization → Fact-Checking.\n",
    "- The topic is dynamically provided at runtime, making the workflow flexible for any research topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ccad36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Crew, Process\n",
    "\n",
    "research_crew = Crew(\n",
    "    agents=[research_agent, summarizer_agent, fact_checker_agent],\n",
    "    tasks=[research_task, summarization_task, fact_checking_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "result = research_crew.kickoff(inputs={\"topic\": \"The impact of AI on job markets\"})\n",
    "print(\"\\nFinal Verified Summary:\\n\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
